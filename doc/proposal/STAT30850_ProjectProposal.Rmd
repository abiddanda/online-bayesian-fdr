---
title: "STAT 30850 Project Proposal"
author: 
  - Arjun Biddanda (abiddanda@uchicago.edu)
  - Joseph Marcus (jhmarcus@uchicago.edu)
date: \today
header-includes:
   - \usepackage{amsmath}
   - \usepackage{amsthm}
fontsize: 11pt
output: pdf_document
---

# Overview

There are many scenarios where hypothesis testing is performed sequentially as new data becomes available through time. Streaming data is common in many modern applications such as high frequency stock trading, novel results from clinical trials, and large-scale advertisement experiments conducted by Google and Facebook. In this context one would like to test multiple hypotheses on the data as it is streaming in, while still retaining adequate FDR control, similarly to approaches developed for non-streaming data. Here we propose to extend and apply Bayesian methods for FDR control in an online testing setting. 

# Setup

Suppose that time $t \in \{0, 1,\dots, n \}$, and that test statistics $X_t$, from some experiment, are independently and identically distributed under the mixture model: $$X_t \sim \pi_0\cdot N(\mu_0, \sigma^2_0) + (1-\pi_0)\cdot N(\mu_1, \sigma^2_1)$$

<!-- Might be a little confusing to have Z-scores as X_t? -->

For instance we could imagine $X_t$ are Z scores such that $\mu_0 = 0$ and $\sigma_0^2 = 1$. Our goal is to estimate the mixture model $\{\pi_0, \mu_1, \sigma^2_1 \}$ for each $t$ as we observe a new $X_t$. We plan to control for FDR at the appropriate level $\alpha$ under the estimated mixture model at time $t$, for simplicity call it $M_t$. 

# Approach 

We propose to use Markov Chain Monte Carlo (MCMC) to sample from the posterior distributions of $\{\pi_0, \mu_1, \sigma^2_1 \}$ allowing us to do inference of $M_t$ and providing measures of uncertainty in these parameters at each time step or at some interval of time. To this end we set priors distributions on $\{\pi_0, \mu_1, \sigma^2_1 \}$:

$$\pi_0 \sim Beta(\alpha, \beta)$$
$$\mu_1 \sim Normal(\mu_s, \tau_s)$$
$$\sigma_1^2 \sim Inverse-Gamma(\alpha^{*}, \beta^{*})$$

If $Z$ is a latent indicator for $X_t$ being a signal then $P(Z = 0) = \pi_0$ and $P(Z = 1) = 1 - \pi_0$. From the above mixture we know:

$$X_t \mid Z = 0 \sim N(0, 1)$$
$$X_t \mid Z = 1 \sim N(\mu_1, \sigma^2_1)$$

If we observe $t$ test statistics at time $t$ we can compute the likelihood of the $M_t$ as:

$$L(M_t) = P(X_1, \dots, X_t \mid \pi_0, \mu_1, \sigma_1) = \prod_{i=1}^{t}(\pi_0\cdot P(X_i \mid Z = 0) + (1 - \pi_0)\cdot P(X_i \mid Z = 1))$$ 

From Bayes Theorem 

$$P(\pi_0, \mu_1, \sigma_1 \mid X_1, \dots, X_t) \propto P(\pi_0)\cdot P(\mu_1)\cdot P(\sigma_1)\cdot P(X_1, \dots, X_t \mid \pi_0, \mu_1, \sigma_1)$$

We plan to sample from this posterior distribution using a component-wise Metropolis-Hasting algorithm with a symmetric proposal distribution and acceptance ratios defined from the above priors and likelihood. We plan to test this approach empirically via simulations where we know the true mixture component distributions and proportions as seen below.

# Z-Scores Simulated from Mixture

```{r, echo=FALSE}
source("../../src/simulation/simulate_mixture.R")
N <- 5000
test.df <- sim.mixture.2comp(N, 0.90, mu1 = 3, sigma1=1)
t <- seq(1,N)
par(mfrow=c(1,2))
plot(t, test.df$Z, type='l', ylab="Z", xlab="t")
hist(test.df$Z, breaks=100, main="", xlab="Z")
```

Above is a time-series of independent samples of Z-scores that are from the mixture distribution with parameters $\pi_0 = 0.90, \mu_1 = 3, \sigma_1^2 = 1$.  


# Questions Proposed

\begin{itemize}
  \item Exploring efficient ways to sample from posterior of the mixture. Potential to sample periodically from the time series, rather than every time-step.  
  \item Setting $\alpha^*$ to have low FDR at beginning ($ t < \tau$), because of uncertainty in inferred mixture model. Explore methods to be conservative based on credible intervals of the posterior distributions of the parameters. 
  \item $\pi_0$ : How many nulls are there relative to the signals within the data? Are we able to detect the signals even when there are very few of them?
  \item $\mu_1 >> 0$ : The relative strength of the signals vs. the nulls. How can we classify weak signals?
  \item Comparison of our Bayesian method against LBOND/LBORD or a sequential version of Storey's method.
  \item Clustering of Signals : How does the method react to clusters of signals together? Varying levels/direction of correlation amongst signals.
\end{itemize}


